{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray,\n",
       " (150, 4),\n",
       " numpy.ndarray,\n",
       " (150,),\n",
       " ['sepal length (cm)',\n",
       "  'sepal width (cm)',\n",
       "  'petal length (cm)',\n",
       "  'petal width (cm)'],\n",
       " ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = load_iris()\n",
    "iris_data = iris.data\n",
    "iris_label = iris.target\n",
    "iris_columns = list(map(lambda x: x.replace(' (cm)', '').replace('al ', 'al_'), iris.feature_names))\n",
    "\n",
    "type(iris_data), iris_data.shape, type(iris_label), iris_label.shape, iris.feature_names, iris_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: loading settings :: url = jar:file:/workspace/apache-spark-ml/.venv/lib/python3.8/site-packages/pyspark/jars/ivy-2.5.1.jar!/org/apache/ivy/core/settings/ivysettings.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ivy Default Cache set to: /root/.ivy2/cache\n",
      "The jars for the packages stored in: /root/.ivy2/jars\n",
      "org.mlflow#mlflow-spark added as a dependency\n",
      ":: resolving dependencies :: org.apache.spark#spark-submit-parent-b4ac4571-095b-4c70-abd2-aa1292857581;1.0\n",
      "\tconfs: [default]\n",
      "\tfound org.mlflow#mlflow-spark;1.11.0 in central\n",
      "\tfound org.slf4j#slf4j-api;1.7.25 in central\n",
      ":: resolution report :: resolve 301ms :: artifacts dl 13ms\n",
      "\t:: modules in use:\n",
      "\torg.mlflow#mlflow-spark;1.11.0 from central in [default]\n",
      "\torg.slf4j#slf4j-api;1.7.25 from central in [default]\n",
      "\t---------------------------------------------------------------------\n",
      "\t|                  |            modules            ||   artifacts   |\n",
      "\t|       conf       | number| search|dwnlded|evicted|| number|dwnlded|\n",
      "\t---------------------------------------------------------------------\n",
      "\t|      default     |   2   |   0   |   0   |   0   ||   2   |   0   |\n",
      "\t---------------------------------------------------------------------\n",
      ":: retrieving :: org.apache.spark#spark-submit-parent-b4ac4571-095b-4c70-abd2-aa1292857581\n",
      "\tconfs: [default]\n",
      "\t0 artifacts copied, 2 already retrieved (0kB/26ms)\n",
      "23/06/05 11:11:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://bac044c6c4c0:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f8c74b81f70>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import mlflow\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.config(\"spark.jars.packages\", \"org.mlflow:mlflow-spark:1.11.0\")\n",
    "    .master(\"local[*]\")\n",
    "    .getOrCreate()\n",
    ")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000\")\n",
    "mlflow.pyspark.ml.autolog()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|target|\n",
      "+------------+-----------+------------+-----------+------+\n",
      "|         5.1|        3.5|         1.4|        0.2|     0|\n",
      "|         4.9|        3.0|         1.4|        0.2|     0|\n",
      "|         4.7|        3.2|         1.3|        0.2|     0|\n",
      "|         4.6|        3.1|         1.5|        0.2|     0|\n",
      "|         5.0|        3.6|         1.4|        0.2|     0|\n",
      "|         5.4|        3.9|         1.7|        0.4|     0|\n",
      "|         4.6|        3.4|         1.4|        0.3|     0|\n",
      "|         5.0|        3.4|         1.5|        0.2|     0|\n",
      "|         4.4|        2.9|         1.4|        0.2|     0|\n",
      "|         4.9|        3.1|         1.5|        0.1|     0|\n",
      "|         5.4|        3.7|         1.5|        0.2|     0|\n",
      "|         4.8|        3.4|         1.6|        0.2|     0|\n",
      "|         4.8|        3.0|         1.4|        0.1|     0|\n",
      "|         4.3|        3.0|         1.1|        0.1|     0|\n",
      "|         5.8|        4.0|         1.2|        0.2|     0|\n",
      "|         5.7|        4.4|         1.5|        0.4|     0|\n",
      "|         5.4|        3.9|         1.3|        0.4|     0|\n",
      "|         5.1|        3.5|         1.4|        0.3|     0|\n",
      "|         5.7|        3.8|         1.7|        0.3|     0|\n",
      "|         5.1|        3.8|         1.5|        0.3|     0|\n",
      "+------------+-----------+------------+-----------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "iris_pdf = pd.DataFrame(iris_data, columns=iris_columns)\n",
    "iris_pdf['target'] = iris_label\n",
    "iris_sdf = spark.createDataFrame(iris_pdf)\n",
    "iris_sdf.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "train_sdf, test_sdf = iris_sdf.randomSplit([0.7, 0.3], seed=0)\n",
    "vector_assembler = VectorAssembler(inputCols=iris_columns, outputCol='features')\n",
    "train_sdf_vectorized = vector_assembler.transform(train_sdf)\n",
    "dt = DecisionTreeClassifier(featuresCol='features', labelCol='target', maxDepth=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/05 11:12:37 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID 'adc701312b334efc879c5e845e498d73', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pyspark.ml workflow\n",
      "2023/06/05 11:13:14 WARNING mlflow.pyspark.ml: Model inputs contain unsupported Spark data types: [StructField('features', VectorUDT(), True)]. Model signature is not logged.\n",
      "23/06/05 11:13:44 ERROR Instrumentation: org.apache.hadoop.fs.UnsupportedFileSystemException: No FileSystem for scheme \"mlflow-artifacts\"\n",
      "\tat org.apache.hadoop.fs.FileSystem.getFileSystemClass(FileSystem.java:3443)\n",
      "\tat org.apache.hadoop.fs.FileSystem.createFileSystem(FileSystem.java:3466)\n",
      "\tat org.apache.hadoop.fs.FileSystem.access$300(FileSystem.java:174)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache.getInternal(FileSystem.java:3574)\n",
      "\tat org.apache.hadoop.fs.FileSystem$Cache.get(FileSystem.java:3521)\n",
      "\tat org.apache.hadoop.fs.FileSystem.get(FileSystem.java:540)\n",
      "\tat org.apache.hadoop.fs.Path.getFileSystem(Path.java:365)\n",
      "\tat org.apache.spark.ml.util.FileSystemOverwrite.handleOverwrite(ReadWrite.scala:673)\n",
      "\tat org.apache.spark.ml.util.MLWriter.save(ReadWrite.scala:167)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.super$save(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$4(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent(events.scala:174)\n",
      "\tat org.apache.spark.ml.MLEvents.withSaveInstanceEvent$(events.scala:169)\n",
      "\tat org.apache.spark.ml.util.Instrumentation.withSaveInstanceEvent(Instrumentation.scala:42)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.$anonfun$save$3$adapted(Pipeline.scala:344)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.$anonfun$instrumented$1(Instrumentation.scala:191)\n",
      "\tat scala.util.Try$.apply(Try.scala:213)\n",
      "\tat org.apache.spark.ml.util.Instrumentation$.instrumented(Instrumentation.scala:191)\n",
      "\tat org.apache.spark.ml.PipelineModel$PipelineModelWriter.save(Pipeline.scala:344)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\n",
      "\tat java.base/jdk.internal.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\n",
      "\tat java.base/jdk.internal.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\n",
      "\tat java.base/java.lang.reflect.Method.invoke(Method.java:566)\n",
      "\tat py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:244)\n",
      "\tat py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:374)\n",
      "\tat py4j.Gateway.invoke(Gateway.java:282)\n",
      "\tat py4j.commands.AbstractCommand.invokeMethod(AbstractCommand.java:132)\n",
      "\tat py4j.commands.CallCommand.execute(CallCommand.java:79)\n",
      "\tat py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "\tat py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "\tat java.base/java.lang.Thread.run(Thread.java:829)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "param_grid = ParamGridBuilder().addGrid(dt.maxDepth, [5, 10])   \\\n",
    "                                .addGrid(dt.minInstancesPerNode, [3, 6])   \\\n",
    "                                .build()\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(labelCol='target', predictionCol='prediction', metricName='accuracy')\n",
    "cv = CrossValidator(estimator=dt, estimatorParamMaps=param_grid, evaluator=evaluator_accuracy, numFolds=3)\n",
    "cv_model = cv.fit(train_sdf_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.tuning.CrossValidatorModel"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(cv_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " [{Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
       "   Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3},\n",
       "  {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
       "   Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 6},\n",
       "  {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
       "   Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3},\n",
       "  {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
       "   Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 6}])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(param_grid), param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'uid': 'CrossValidatorModel_b84077e485ed',\n",
       " '_paramMap': {Param(parent='CrossValidatorModel_b84077e485ed', name='estimator', doc='estimator to be cross-validated'): DecisionTreeClassifier_79cf0245c728,\n",
       "  Param(parent='CrossValidatorModel_b84077e485ed', name='estimatorParamMaps', doc='estimator param maps'): [{Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
       "    Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3},\n",
       "   {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
       "    Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 6},\n",
       "   {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
       "    Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3},\n",
       "   {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
       "    Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 6}],\n",
       "  Param(parent='CrossValidatorModel_b84077e485ed', name='evaluator', doc='evaluator used to select hyper-parameters that maximize the validator metric'): MulticlassClassificationEvaluator_63535fe4e11f,\n",
       "  Param(parent='CrossValidatorModel_b84077e485ed', name='numFolds', doc='number of folds for cross validation'): 3},\n",
       " '_defaultParamMap': {Param(parent='CrossValidatorModel_b84077e485ed', name='seed', doc='random seed.'): 8457801743217767709,\n",
       "  Param(parent='CrossValidatorModel_b84077e485ed', name='numFolds', doc='number of folds for cross validation'): 3,\n",
       "  Param(parent='CrossValidatorModel_b84077e485ed', name='foldCol', doc=\"Param for the column name of user specified fold number. Once this is specified, :py:class:`CrossValidator` won't do random k-fold split. Note that this column should be integer type with range [0, numFolds) and Spark will throw exception on out-of-range fold numbers.\"): ''},\n",
       " '_params': None,\n",
       " 'estimator': Param(parent='CrossValidatorModel_b84077e485ed', name='estimator', doc='estimator to be cross-validated'),\n",
       " 'estimatorParamMaps': Param(parent='CrossValidatorModel_b84077e485ed', name='estimatorParamMaps', doc='estimator param maps'),\n",
       " 'evaluator': Param(parent='CrossValidatorModel_b84077e485ed', name='evaluator', doc='evaluator used to select hyper-parameters that maximize the validator metric'),\n",
       " 'foldCol': Param(parent='CrossValidatorModel_b84077e485ed', name='foldCol', doc=\"Param for the column name of user specified fold number. Once this is specified, :py:class:`CrossValidator` won't do random k-fold split. Note that this column should be integer type with range [0, numFolds) and Spark will throw exception on out-of-range fold numbers.\"),\n",
       " 'numFolds': Param(parent='CrossValidatorModel_b84077e485ed', name='numFolds', doc='number of folds for cross validation'),\n",
       " 'seed': Param(parent='CrossValidatorModel_b84077e485ed', name='seed', doc='random seed.'),\n",
       " 'bestModel': DecisionTreeClassificationModel: uid=DecisionTreeClassifier_79cf0245c728, depth=4, numNodes=9, numClasses=3, numFeatures=4,\n",
       " 'avgMetrics': [0.9239774114774114,\n",
       "  0.9154304029304029,\n",
       "  0.9239774114774114,\n",
       "  0.9154304029304029],\n",
       " 'subModels': None,\n",
       " 'stdMetrics': [0.027440975301341073,\n",
       "  0.021821885097057396,\n",
       "  0.027440975301341073,\n",
       "  0.021821885097057396]}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
       "  Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3},\n",
       " {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
       "  Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 6},\n",
       " {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
       "  Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3},\n",
       " {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
       "  Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 6}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model.getEstimatorParamMaps()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.9239774114774114,\n",
       "  {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
       "   Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3}),\n",
       " (0.9154304029304029,\n",
       "  {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
       "   Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 6}),\n",
       " (0.9239774114774114,\n",
       "  {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
       "   Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3}),\n",
       " (0.9154304029304029,\n",
       "  {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
       "   Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 6})]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(cv_model.avgMetrics, cv_model.getEstimatorParamMaps()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
       "  Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3},\n",
       " {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 5,\n",
       "  Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 6},\n",
       " {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
       "  Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 3},\n",
       " {Param(parent='DecisionTreeClassifier_79cf0245c728', name='maxDepth', doc='Maximum depth of the tree. (>= 0) E.g., depth 0 means 1 leaf node; depth 1 means 1 internal node + 2 leaf nodes. Must be in range [0, 30].'): 10,\n",
       "  Param(parent='DecisionTreeClassifier_79cf0245c728', name='minInstancesPerNode', doc='Minimum number of instances each child must have after split. If a split causes the left or right child to have fewer than minInstancesPerNode, the split will be discarded as invalid. Should be >= 1.'): 6}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[m for m in cv_model.getEstimatorParamMaps()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'maxDepth': 5, 'minInstancesPerNode': 3},\n",
       " {'maxDepth': 5, 'minInstancesPerNode': 6},\n",
       " {'maxDepth': 10, 'minInstancesPerNode': 3},\n",
       " {'maxDepth': 10, 'minInstancesPerNode': 6}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [{p.name: v for p, v in m.items() } for m in cv_model.getEstimatorParamMaps()]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'maxDepth': 5, 'minInstancesPerNode': 3},\n",
       " {'maxDepth': 5, 'minInstancesPerNode': 6},\n",
       " {'maxDepth': 10, 'minInstancesPerNode': 3},\n",
       " {'maxDepth': 10, 'minInstancesPerNode': 6}]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [{p.name: v for p, v in m.items() } for m in cv_model.getEstimatorParamMaps()]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>evaluation_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 3}</td>\n",
       "      <td>0.923977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 6}</td>\n",
       "      <td>0.915430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 3}</td>\n",
       "      <td>0.923977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 6}</td>\n",
       "      <td>0.915430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       params  evaluation_result\n",
       "0   {'maxDepth': 5, 'minInstancesPerNode': 3}           0.923977\n",
       "1   {'maxDepth': 5, 'minInstancesPerNode': 6}           0.915430\n",
       "2  {'maxDepth': 10, 'minInstancesPerNode': 3}           0.923977\n",
       "3  {'maxDepth': 10, 'minInstancesPerNode': 6}           0.915430"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(zip(params, cv_model.avgMetrics))\n",
    "cv_result = pd.DataFrame({'params': params, 'evaluation_result': cv_model.avgMetrics})\n",
    "cv_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cv_result_pdf(cv_model):\n",
    "    params = [{p.name: v for p, v in m.items()} for m in cv_model.getEstimatorParamMaps()]\n",
    "    return pd.DataFrame({'params': params, 'evaluation_result': cv_model.avgMetrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+------+-----------------+--------------+--------------------+----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|target|         features| rawPrediction|         probability|prediction|\n",
      "+------------+-----------+------------+-----------+------+-----------------+--------------+--------------------+----------+\n",
      "|         4.6|        3.1|         1.5|        0.2|     0|[4.6,3.1,1.5,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.1|        3.5|         1.4|        0.2|     0|[5.1,3.5,1.4,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.0|        3.4|         1.5|        0.2|     0|[5.0,3.4,1.5,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.4|        3.7|         1.5|        0.2|     0|[5.4,3.7,1.5,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.7|        4.4|         1.5|        0.4|     0|[5.7,4.4,1.5,0.4]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.1|        3.7|         1.5|        0.4|     0|[5.1,3.7,1.5,0.4]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.1|        3.8|         1.5|        0.3|     0|[5.1,3.8,1.5,0.3]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         4.7|        3.2|         1.6|        0.2|     0|[4.7,3.2,1.6,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.0|        3.2|         1.2|        0.2|     0|[5.0,3.2,1.2,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         4.5|        2.3|         1.3|        0.3|     0|[4.5,2.3,1.3,0.3]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.0|        3.5|         1.3|        0.3|     0|[5.0,3.5,1.3,0.3]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.1|        3.4|         1.5|        0.2|     0|[5.1,3.4,1.5,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         4.8|        3.0|         1.4|        0.3|     0|[4.8,3.0,1.4,0.3]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.1|        3.8|         1.9|        0.4|     0|[5.1,3.8,1.9,0.4]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.3|        3.7|         1.5|        0.2|     0|[5.3,3.7,1.5,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         6.9|        3.1|         4.9|        1.5|     1|[6.9,3.1,4.9,1.5]| [0.0,2.0,1.0]|[0.0,0.6666666666...|       1.0|\n",
      "|         4.9|        2.4|         3.3|        1.0|     1|[4.9,2.4,3.3,1.0]|[0.0,31.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|         6.5|        2.8|         4.6|        1.5|     1|[6.5,2.8,4.6,1.5]|[0.0,31.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|         6.6|        2.9|         4.6|        1.3|     1|[6.6,2.9,4.6,1.3]|[0.0,31.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|         5.6|        2.9|         3.6|        1.3|     1|[5.6,2.9,3.6,1.3]|[0.0,31.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "+------------+-----------+------------+-----------+------+-----------------+--------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sdf_vectorized = vector_assembler.transform(test_sdf)\n",
    "predictions = cv_model.transform(test_sdf_vectorized)\n",
    "predictions.show()\n",
    "evaluation_accuracy = MulticlassClassificationEvaluator(labelCol='target', predictionCol='prediction')\n",
    "evaluation_accuracy.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassificationModel: uid=DecisionTreeClassifier_79cf0245c728, depth=4, numNodes=9, numClasses=3, numFeatures=4"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt_model = cv_model.bestModel\n",
    "best_dt_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-----------+------------+-----------+------+-----------------+--------------+--------------------+----------+\n",
      "|sepal_length|sepal_width|petal_length|petal_width|target|         features| rawPrediction|         probability|prediction|\n",
      "+------------+-----------+------------+-----------+------+-----------------+--------------+--------------------+----------+\n",
      "|         4.6|        3.1|         1.5|        0.2|     0|[4.6,3.1,1.5,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.1|        3.5|         1.4|        0.2|     0|[5.1,3.5,1.4,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.0|        3.4|         1.5|        0.2|     0|[5.0,3.4,1.5,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.4|        3.7|         1.5|        0.2|     0|[5.4,3.7,1.5,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.7|        4.4|         1.5|        0.4|     0|[5.7,4.4,1.5,0.4]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.1|        3.7|         1.5|        0.4|     0|[5.1,3.7,1.5,0.4]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.1|        3.8|         1.5|        0.3|     0|[5.1,3.8,1.5,0.3]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         4.7|        3.2|         1.6|        0.2|     0|[4.7,3.2,1.6,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.0|        3.2|         1.2|        0.2|     0|[5.0,3.2,1.2,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         4.5|        2.3|         1.3|        0.3|     0|[4.5,2.3,1.3,0.3]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.0|        3.5|         1.3|        0.3|     0|[5.0,3.5,1.3,0.3]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.1|        3.4|         1.5|        0.2|     0|[5.1,3.4,1.5,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         4.8|        3.0|         1.4|        0.3|     0|[4.8,3.0,1.4,0.3]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.1|        3.8|         1.9|        0.4|     0|[5.1,3.8,1.9,0.4]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         5.3|        3.7|         1.5|        0.2|     0|[5.3,3.7,1.5,0.2]|[35.0,0.0,0.0]|       [1.0,0.0,0.0]|       0.0|\n",
      "|         6.9|        3.1|         4.9|        1.5|     1|[6.9,3.1,4.9,1.5]| [0.0,2.0,1.0]|[0.0,0.6666666666...|       1.0|\n",
      "|         4.9|        2.4|         3.3|        1.0|     1|[4.9,2.4,3.3,1.0]|[0.0,31.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|         6.5|        2.8|         4.6|        1.5|     1|[6.5,2.8,4.6,1.5]|[0.0,31.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|         6.6|        2.9|         4.6|        1.3|     1|[6.6,2.9,4.6,1.3]|[0.0,31.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "|         5.6|        2.9|         3.6|        1.3|     1|[5.6,2.9,3.6,1.3]|[0.0,31.0,0.0]|       [0.0,1.0,0.0]|       1.0|\n",
      "+------------+-----------+------------+-----------+------+-----------------+--------------+--------------------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_model_predictions = best_dt_model.transform(test_sdf_vectorized)\n",
    "best_model_predictions.show()\n",
    "evaluation_accuracy.evaluate(best_model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>evaluation_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 3}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 5}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 6}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'maxDepth': 7, 'minInstancesPerNode': 3}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'maxDepth': 7, 'minInstancesPerNode': 5}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'maxDepth': 7, 'minInstancesPerNode': 6}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'maxDepth': 8, 'minInstancesPerNode': 3}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'maxDepth': 8, 'minInstancesPerNode': 5}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'maxDepth': 8, 'minInstancesPerNode': 6}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 3}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 5}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 6}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        params  evaluation_result\n",
       "0    {'maxDepth': 5, 'minInstancesPerNode': 3}            0.93331\n",
       "1    {'maxDepth': 5, 'minInstancesPerNode': 5}            0.93331\n",
       "2    {'maxDepth': 5, 'minInstancesPerNode': 6}            0.93331\n",
       "3    {'maxDepth': 7, 'minInstancesPerNode': 3}            0.93331\n",
       "4    {'maxDepth': 7, 'minInstancesPerNode': 5}            0.93331\n",
       "5    {'maxDepth': 7, 'minInstancesPerNode': 6}            0.93331\n",
       "6    {'maxDepth': 8, 'minInstancesPerNode': 3}            0.93331\n",
       "7    {'maxDepth': 8, 'minInstancesPerNode': 5}            0.93331\n",
       "8    {'maxDepth': 8, 'minInstancesPerNode': 6}            0.93331\n",
       "9   {'maxDepth': 10, 'minInstancesPerNode': 3}            0.93331\n",
       "10  {'maxDepth': 10, 'minInstancesPerNode': 5}            0.93331\n",
       "11  {'maxDepth': 10, 'minInstancesPerNode': 6}            0.93331"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml import Pipeline\n",
    "\n",
    "train_sdf, test_sdf = iris_sdf.randomSplit([0.7, 0.3], seed=0)\n",
    "stage_1 = VectorAssembler(inputCols=iris_columns, outputCol='features')\n",
    "stage_2 = DecisionTreeClassifier(featuresCol='features', labelCol='target', maxDepth=10)\n",
    "pipeline_1 = Pipeline(stages=[stage_1, stage_2])\n",
    "\n",
    "param_grid_1 = ParamGridBuilder().addGrid(stage_2.maxDepth, [5, 7, 8, 10])   \\\n",
    "                                .addGrid(stage_2.minInstancesPerNode, [3, 5, 6])    \\\n",
    "                                .build()\n",
    "evaluation_accuracy_1 = MulticlassClassificationEvaluator(labelCol='target', predictionCol='prediction', metricName='accuracy')\n",
    "cv = CrossValidator(estimator=pipeline_1, estimatorParamMaps=param_grid_1, evaluator=evaluation_accuracy_1, numFolds=3)\n",
    "cv_model_1 = cv.fit(train_sdf)\n",
    "cv_result_pdf = get_cv_result_pdf(cv_model_1)\n",
    "cv_result_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_1 = cv_model_1.transform(test_sdf)\n",
    "evaluation_accuracy_1.evaluate(predictions_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/05 10:29:26 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during spark autologging: Exception while attempting to initialize JVM-side state for Spark datasource autologging. Please create a new Spark session and ensure you have the mlflow-spark JAR attached to your Spark session as described in http://mlflow.org/docs/latest/tracking.html#automatic-logging-from-spark-experimental. Exception:\n",
      "'JavaPackage' object is not callable\n",
      "2023/06/05 10:29:26 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '3586fe17e9624d20aa0597adb1f2d2b6', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pyspark.ml workflow\n",
      "23/06/05 10:29:33 WARN BlockManager: Asked to remove block broadcast_6553, which does not exist\n",
      "2023/06/05 10:30:52 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during pyspark.ml autologging: The configured tracking uri scheme: 'file' is invalid for use with the proxy mlflow-artifact scheme. The allowed tracking schemes are: {'http', 'https'}\n"
     ]
    }
   ],
   "source": [
    "stage_vectorized = VectorAssembler(inputCols=iris_columns, outputCol='features')\n",
    "dt_estimator = DecisionTreeClassifier(featuresCol='features', labelCol='target')\n",
    "param_grid_2 = ParamGridBuilder().addGrid(dt_estimator.maxDepth, [5, 7, 8, 10]) \\\n",
    "                                .addGrid(dt_estimator.minInstancesPerNode, [3, 5, 6]) \\\n",
    "                                .build()\n",
    "evaluation_accuracy = MulticlassClassificationEvaluator(labelCol='target', predictionCol='prediction', metricName='accuracy')\n",
    "stage_cv = CrossValidator(estimator=dt_estimator, estimatorParamMaps=param_grid_2, evaluator=evaluation_accuracy, numFolds=3)\n",
    "pipeline_2 = Pipeline(stages=[stage_vectorized, stage_cv])\n",
    "pipeline_model_2 = pipeline_2.fit(train_sdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.ml.tuning.CrossValidatorModel"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_model_2.stages\n",
    "type(pipeline_model_2.stages[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>evaluation_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 3}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 5}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 6}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'maxDepth': 7, 'minInstancesPerNode': 3}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'maxDepth': 7, 'minInstancesPerNode': 5}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'maxDepth': 7, 'minInstancesPerNode': 6}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'maxDepth': 8, 'minInstancesPerNode': 3}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'maxDepth': 8, 'minInstancesPerNode': 5}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'maxDepth': 8, 'minInstancesPerNode': 6}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 3}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 5}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 6}</td>\n",
       "      <td>0.93331</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        params  evaluation_result\n",
       "0    {'maxDepth': 5, 'minInstancesPerNode': 3}            0.93331\n",
       "1    {'maxDepth': 5, 'minInstancesPerNode': 5}            0.93331\n",
       "2    {'maxDepth': 5, 'minInstancesPerNode': 6}            0.93331\n",
       "3    {'maxDepth': 7, 'minInstancesPerNode': 3}            0.93331\n",
       "4    {'maxDepth': 7, 'minInstancesPerNode': 5}            0.93331\n",
       "5    {'maxDepth': 7, 'minInstancesPerNode': 6}            0.93331\n",
       "6    {'maxDepth': 8, 'minInstancesPerNode': 3}            0.93331\n",
       "7    {'maxDepth': 8, 'minInstancesPerNode': 5}            0.93331\n",
       "8    {'maxDepth': 8, 'minInstancesPerNode': 6}            0.93331\n",
       "9   {'maxDepth': 10, 'minInstancesPerNode': 3}            0.93331\n",
       "10  {'maxDepth': 10, 'minInstancesPerNode': 5}            0.93331\n",
       "11  {'maxDepth': 10, 'minInstancesPerNode': 6}            0.93331"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_model_2 = pipeline_model_2.stages[-1]\n",
    "cv_result_pdf = get_cv_result_pdf(cv_model_2)\n",
    "cv_result_pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = pipeline_model_2.transform(test_sdf)\n",
    "evaluation_accuracy.evaluate(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023/06/05 10:30:53 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during spark autologging: Exception while attempting to initialize JVM-side state for Spark datasource autologging. Please create a new Spark session and ensure you have the mlflow-spark JAR attached to your Spark session as described in http://mlflow.org/docs/latest/tracking.html#automatic-logging-from-spark-experimental. Exception:\n",
      "'JavaPackage' object is not callable\n",
      "2023/06/05 10:30:53 INFO mlflow.utils.autologging_utils: Created MLflow autologging run with ID '9d112cf81cfc42b986bc0834c46cc300', which will track hyperparameters, performance metrics, model artifacts, and lineage information for the current pyspark.ml workflow\n",
      "2023/06/05 10:31:20 WARNING mlflow.utils.autologging_utils: Encountered unexpected error during pyspark.ml autologging: The configured tracking uri scheme: 'file' is invalid for use with the proxy mlflow-artifact scheme. The allowed tracking schemes are: {'http', 'https'}\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import TrainValidationSplit, ParamGridBuilder\n",
    "\n",
    "vector_assembler = VectorAssembler(inputCols=iris_columns, outputCol='features')\n",
    "train_sdf_vectorized = vector_assembler.transform(train_sdf)\n",
    "dt_estimator = DecisionTreeClassifier(featuresCol='features', labelCol='target', maxDepth=10)\n",
    "tvs_param_grid = ParamGridBuilder().addGrid(dt_estimator.maxDepth, [5, 7, 8, 10])   \\\n",
    "                                    .addGrid(dt_estimator.minInstancesPerNode, [3, 5, 6])   \\\n",
    "                                    .build()\n",
    "evaluation_accuracy = MulticlassClassificationEvaluator(labelCol='target', predictionCol='prediction', metricName='accuracy')\n",
    "tvs = TrainValidationSplit(estimator=dt_estimator, estimatorParamMaps=tvs_param_grid, evaluator=evaluation_accuracy, trainRatio=0.75, seed=0)\n",
    "tvs_model = tvs.fit(train_sdf_vectorized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tvs_model.validationMetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'maxDepth': 5, 'minInstancesPerNode': 3},\n",
       " {'maxDepth': 5, 'minInstancesPerNode': 5},\n",
       " {'maxDepth': 5, 'minInstancesPerNode': 6},\n",
       " {'maxDepth': 7, 'minInstancesPerNode': 3},\n",
       " {'maxDepth': 7, 'minInstancesPerNode': 5},\n",
       " {'maxDepth': 7, 'minInstancesPerNode': 6},\n",
       " {'maxDepth': 8, 'minInstancesPerNode': 3},\n",
       " {'maxDepth': 8, 'minInstancesPerNode': 5},\n",
       " {'maxDepth': 8, 'minInstancesPerNode': 6},\n",
       " {'maxDepth': 10, 'minInstancesPerNode': 3},\n",
       " {'maxDepth': 10, 'minInstancesPerNode': 5},\n",
       " {'maxDepth': 10, 'minInstancesPerNode': 6}]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = [{p.name: v for p, v in m.items()} for m in tvs_model.getEstimatorParamMaps()]\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tvs_result_pdf(tvs_model):\n",
    "    params = [{p.name: v for p, v in m.items()} for m in tvs_model.getEstimatorParamMaps()]\n",
    "    return pd.DataFrame({'params': params, 'evaluation_result': tvs_model.validationMetrics})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>evaluation_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 3}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 5}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'maxDepth': 5, 'minInstancesPerNode': 6}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'maxDepth': 7, 'minInstancesPerNode': 3}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'maxDepth': 7, 'minInstancesPerNode': 5}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'maxDepth': 7, 'minInstancesPerNode': 6}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>{'maxDepth': 8, 'minInstancesPerNode': 3}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>{'maxDepth': 8, 'minInstancesPerNode': 5}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>{'maxDepth': 8, 'minInstancesPerNode': 6}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 3}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 5}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>{'maxDepth': 10, 'minInstancesPerNode': 6}</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        params  evaluation_result\n",
       "0    {'maxDepth': 5, 'minInstancesPerNode': 3}                1.0\n",
       "1    {'maxDepth': 5, 'minInstancesPerNode': 5}                1.0\n",
       "2    {'maxDepth': 5, 'minInstancesPerNode': 6}                1.0\n",
       "3    {'maxDepth': 7, 'minInstancesPerNode': 3}                1.0\n",
       "4    {'maxDepth': 7, 'minInstancesPerNode': 5}                1.0\n",
       "5    {'maxDepth': 7, 'minInstancesPerNode': 6}                1.0\n",
       "6    {'maxDepth': 8, 'minInstancesPerNode': 3}                1.0\n",
       "7    {'maxDepth': 8, 'minInstancesPerNode': 5}                1.0\n",
       "8    {'maxDepth': 8, 'minInstancesPerNode': 6}                1.0\n",
       "9   {'maxDepth': 10, 'minInstancesPerNode': 3}                1.0\n",
       "10  {'maxDepth': 10, 'minInstancesPerNode': 5}                1.0\n",
       "11  {'maxDepth': 10, 'minInstancesPerNode': 6}                1.0"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tvs_result_pdf(tvs_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9545454545454546"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_dt_model = tvs_model.bestModel\n",
    "best_model_predictions = best_dt_model.transform(test_sdf_vectorized)\n",
    "evaluation_accuracy.evaluate(best_model_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
